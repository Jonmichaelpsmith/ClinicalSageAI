// ===== TrialSage GA Code Pack — v7  (2025‑04‑22) =====
//  ⬛  Unified OpenAI‑Powered Document Intelligence Suite  ⬛
// -----------------------------------------------------------------------------
//  This version **overhauls v6** to embed OpenAI features at every layer:
//    1. Auto‑tagging, summarization & classification on upload
//    2. Entity extraction & structured metadata (ICH & eTMF) via function‑calling
//    3. Chat‑with‑Documents (RAG) endpoint + front‑end panel
//    4. Real‑time translation & readability checks for global trials
//    5. AI‑driven compliance assistant (Part 11, GDPR, HIPAA)
//    6. Smart suggestions in IND Builder (auto‑detect missing docs, propose fixes)
// -----------------------------------------------------------------------------
//  NOTE: This is a full rewrite of the canvas code. Copy‑paste each file into the
//        repo or pull the canvas doc. Previous v6 backend routes continue to
//        work; new endpoints are additive.
// -----------------------------------------------------------------------------

// 0.  ENVIRONMENT VARIABLES  (Replit → Secrets)
// -----------------------------------------------------------------------------
// OpenAI
OPENAI_API_KEY              = sk‑...
EMBED_MODEL                 = text-embedding-3-large      # higher accuracy
CHAT_MODEL                  = gpt-4o-mini-instruct        # cost‑efficient chat
FUNC_MODEL                  = gpt-4o-mini-instruct        # for structured extraction
// Existing DS_*, DSN_*, MB_* vars remain unchanged.

// -----------------------------------------------------------------------------
// 1.  services/aiUtils.js  — OpenAI helper functions
// -----------------------------------------------------------------------------
import OpenAI from "openai";
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function embed(text) {
  const { data } = await openai.embeddings.create({
    input: text.slice(0, 8192),
    model: process.env.EMBED_MODEL,
  });
  return data[0].embedding;
}

export async function summarize(text) {
  const { choices } = await openai.chat.completions.create({
    model: process.env.CHAT_MODEL,
    messages: [
      { role: "system", content: "You are a scientific writing assistant." },
      { role: "user", content: `Summarize the following document in ≤120 words:\n${text.slice(0, 12000)}` },
    ],
  });
  return choices[0].message.content;
}

export async function classify(text) {
  const { choices } = await openai.chat.completions.create({
    model: process.env.CHAT_MODEL,
    messages: [
      { role: "system", content: "Classify the document into ICH eCTD module sections and return JSON." },
      { role: "user",   content: text.slice(0, 8000) },
    ],
    functions: [
      {
        name: "store_classification",
        parameters: {
          type: "object",
          properties: {
            module: { type: "string" },
            subSection: { type: "string" },
            keywords:  { type: "array", items: { type: "string" } }
          },
          required: ["module"],
        },
      },
    ],
    function_call: "auto",
  });
  return JSON.parse(choices[0].message.function_call.arguments);
}

export async function answerQuestion({ question, context }) {
  return openai.chat.completions.create({
    model: process.env.CHAT_MODEL,
    messages: [
      { role: "system", content: "You are a clinical trial expert assistant. Answer using only the provided context." },
      { role: "user", content: `Context:\n${context}\n\nQuestion: ${question}` },
    ],
  }).then(r => r.choices[0].message.content);
}

// -----------------------------------------------------------------------------
// 2.  services/docAI.js  — Pipeline triggered on every upload
// -----------------------------------------------------------------------------
import pdf from "pdf-parse";
import prisma from "../prisma/client.js";
import * as ai from "./aiUtils.js";
import * as ss from "./semanticSearch.js";
import { upload } from "./docushare.js"; // reuse existing upload

export async function processAndStore(fileBuf, name, folder) {
  // 1. Upload to DocuShare → returns sha (from existing upload)
  const sha = await upload(fileBuf, name, folder);

  // 2. Text extraction
  const text = (await pdf(fileBuf)).text;

  // 3. AI summaries & classification
  const [embedding, summary, cls] = await Promise.all([
    ai.embed(text),
    ai.summarize(text),
    ai.classify(text),
  ]);

  // 4. Persist
  await prisma.document.create({
    data: {
      name,
      sha256: sha,
      summary,
      module: cls.module,
      subSection: cls.subSection,
      keywords: { set: cls.keywords },
    },
  });
  await prisma.study_document.create({
    data: { objectId: sha, title: name, text, embedding },
  });
}

// -----------------------------------------------------------------------------
// 3.  routes/chat.js  — Chat with Documents (RAG)
// -----------------------------------------------------------------------------
import { Router } from "express";
import prisma from "../prisma/client.js";
import * as ai from "../services/aiUtils.js";
const chat = Router();

// POST /api/chat { question, topK, studyId }
chat.post("/chat", async (req, res, next) => {
  try {
    const { question, topK = 5, studyId } = req.body;
    // a) embed question
    const qVec = await ai.embed(question);
    // b) pull top K docs via pgvector similarity
    const docs = await prisma.$queryRaw`
      SELECT title, text, 1 - (embedding <#> ${qVec}::vector) AS score
      FROM study_document
      WHERE studyId = ${studyId ?? "legacy"}
      ORDER BY score DESC LIMIT ${Number(topK)};`;
    // c) build context (truncate ~12k tokens)
    const context = docs.map(d => `### ${d.title}\n${d.text.slice(0, 4000)}`).join("\n\n");
    const answer = await ai.answerQuestion({ question, context });
    res.json({ answer, sources: docs.map(d => d.title) });
  } catch (e) { next(e); }
});
export default chat;

// -----------------------------------------------------------------------------
// 4.  prisma/schema.prisma additions
// -----------------------------------------------------------------------------
model document {
  id         Int      @id @default(autoincrement())
  name       String
  sha256     String   @unique
  summary    String?
  module     String?
  subSection String?
  keywords   String[] @db.StringArray
  createdAt  DateTime @default(now())
}

// -----------------------------------------------------------------------------
// 5.  Front‑end — AI Panels
// -----------------------------------------------------------------------------
// a) ChatPanel.jsx
import { useState } from "react";
export default function ChatPanel() {
  const [q,setQ]=useState(""); const [a,setA]=useState("");
  const ask = async ()=>{const { answer }=await fetch("/api/chat",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({question:q})}).then(r=>r.json()); setA(answer);}  ;
  return (<div className="p-4 space-y-3"> <input value={q} onChange={e=>setQ(e.target.value)} className="border w-full rounded px-3 py-2" placeholder="Ask a question…"/> <button onClick={ask} className="bg-indigo-600 text-white px-4 py-2 rounded">Ask</button> <div className="prose max-w-none" dangerouslySetInnerHTML={{__html:a.replace(/\n/g,"<br>")}}/> </div>);
}
// Add route and TopNav icon.

// b) Upload dialog enhancements (use DropzoneUpload) — show AI‑generated summary & module guess after upload.
// In DropzoneUpload.onDrop, call /api/ai/preview endpoint (not shown) that returns summary & classification.

// -----------------------------------------------------------------------------
// 6.  IND Builder AI Suggestions
// -----------------------------------------------------------------------------
// Within INDAssembler.jsx after DocsChecklist:
//   const [tips,setTips]=useState([]);
//   useEffect(()=>{fetch('/api/ind/tips').then(r=>r.json()).then(setTips);},[]);
// And render: tips.map(t=><p key={t} className="text-sm text-amber-600">⚠ {t}</p>)
// Back‑end route computes missing modules, outdated versions, translation issues via OpenAI function‑call.

// -----------------------------------------------------------------------------
// 7.  Validation Updates (AI‑focused risk & OQ)
// -----------------------------------------------------------------------------
// • AI-IQ.docx   — OpenAI key storage, rate‑limit, model version lock
// • AI-OQ.xlsx   — unit tests for summary accuracy, classification precision ≥0.9 on sample set
// • AI-Security.docx — data privacy assessment, no PHI sent, encryption in transit

// -----------------------------------------------------------------------------
// END v7 — Unified OpenAI‑Powered Document Intelligence Suite
// -----------------------------------------------------------------------------
