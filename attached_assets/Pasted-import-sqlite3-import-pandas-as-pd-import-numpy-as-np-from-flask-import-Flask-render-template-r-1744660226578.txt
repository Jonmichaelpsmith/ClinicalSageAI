import sqlite3
import pandas as pd
import numpy as np
from flask import Flask, render_template, request
from sentence_transformers import SentenceTransformer, util
import spacy
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import plotly.express as px
import plotly.graph_objects as go
import json

app = Flask(__name__)

# Initialize NLP and ML models
nlp = spacy.load("en_core_web_sm")
model = SentenceTransformer('all-MiniLM-L6-v2')
classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Set up SQLite database
def init_db():
    conn = sqlite3.connect('studies.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS studies (
        id INTEGER PRIMARY KEY,
        therapeutic_area TEXT,
        phase TEXT,
        sample_size INTEGER,
        endpoint TEXT,
        randomization TEXT,
        blinding TEXT,
        outcome TEXT,
        failure_reason TEXT,
        description TEXT
    )''')
    conn.commit()
    conn.close()

# Generate simulated dataset of 3,000 CSRs
def generate_data():
    conn = sqlite3.connect('studies.db')
    c = conn.cursor()
    c.execute("DELETE FROM studies")  # Clear existing data
    np.random.seed(42)
    therapeutic_areas = ["Oncology", "Cardiology", "Neurology", "Immunology"]
    phases = ["Phase I", "Phase II", "Phase III"]
    outcomes = ["Success", "Failure"]
    failure_reasons = ["Lack of Efficacy", "Safety Concerns", "Recruitment Issues", "Protocol Deviation", None]
    randomizations = ["1:1", "2:1", "None"]
    blindings = ["Double-Blind", "Single-Blind", "Open-Label"]

    for i in range(3000):
        therapeutic_area = np.random.choice(therapeutic_areas)
        phase = np.random.choice(phases)
        sample_size = np.random.randint(50, 500)
        endpoint = "PFS" if therapeutic_area == "Oncology" else "OS"
        randomization = np.random.choice(randomizations)
        blinding = np.random.choice(blindings)
        outcome = np.random.choice(outcomes, p=[0.6, 0.4])  # 60% success rate
        failure_reason = np.random.choice(failure_reasons, p=[0.4, 0.3, 0.2, 0.1, 0.0]) if outcome == "Failure" else None
        description = f"{therapeutic_area} {phase} study with {sample_size} participants, targeting {endpoint}."
        c.execute("INSERT INTO studies (therapeutic_area, phase, sample_size, endpoint, randomization, blinding, outcome, failure_reason, description) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                  (therapeutic_area, phase, sample_size, endpoint, randomization, blinding, outcome, failure_reason, description))
    conn.commit()
    conn.close()

# Load data and train ML model
def train_model():
    conn = sqlite3.connect('studies.db')
    df = pd.read_sql_query("SELECT * FROM studies", conn)
    conn.close()

    # Encode categorical variables
    le_therapeutic = LabelEncoder()
    le_phase = LabelEncoder()
    le_randomization = LabelEncoder()
    le_blinding = LabelEncoder()
    le_outcome = LabelEncoder()

    df['therapeutic_area'] = le_therapeutic.fit_transform(df['therapeutic_area'])
    df['phase'] = le_phase.fit_transform(df['phase'])
    df['randomization'] = le_randomization.fit_transform(df['randomization'])
    df['blinding'] = le_blinding.fit_transform(df['blinding'])
    df['outcome'] = le_outcome.fit_transform(df['outcome'])

    X = df[['therapeutic_area', 'phase', 'sample_size', 'randomization', 'blinding']]
    y = df['outcome']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    classifier.fit(X_train, y_train)

    return le_therapeutic, le_phase, le_randomization, le_blinding, le_outcome

# Extract features from user input
def extract_features(text):
    doc = nlp(text)
    therapeutic_area = "Oncology"  # Simplified extraction for demo
    phase = "Phase II"
    sample_size = 150
    endpoint = "PFS"
    randomization = "1:1"
    blinding = "Double-Blind"
    return therapeutic_area, phase, sample_size, endpoint, randomization, blinding

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        protocol = request.form['protocol']
        therapeutic_area, phase, sample_size, endpoint, randomization, blinding = extract_features(protocol)

        # Load data
        conn = sqlite3.connect('studies.db')
        df = pd.read_sql_query("SELECT * FROM studies", conn)
        conn.close()

        # Encode user input
        le_therapeutic, le_phase, le_randomization, le_blinding, le_outcome = train_model()
        user_data = pd.DataFrame({
            'therapeutic_area': [le_therapeutic.transform([therapeutic_area])[0]],
            'phase': [le_phase.transform([phase])[0]],
            'sample_size': [sample_size],
            'randomization': [le_randomization.transform([randomization])[0]],
            'blinding': [le_blinding.transform([blinding])[0]]
        })

        # Predict failure probability
        failure_prob = classifier.predict_proba(user_data)[0][0] * 100  # Probability of failure

        # Find similar studies using embeddings
        user_description = f"{therapeutic_area} {phase} study with {sample_size} participants, targeting {endpoint}."
        user_embedding = model.encode(user_description)
        df['embedding'] = df['description'].apply(lambda x: model.encode(x))
        similarities = df['embedding'].apply(lambda x: util.cos_sim(user_embedding, x).item())
        df['similarity'] = similarities
        similar_studies = df.nlargest(50, 'similarity')

        # Analyze failure reasons
        failure_counts = similar_studies[similar_studies['outcome'] == 'Failure']['failure_reason'].value_counts()
        pie_fig = px.pie(values=failure_counts.values, names=failure_counts.index, title="Failure Reasons in Similar Studies")

        # Similarity distribution
        hist_fig = px.histogram(similar_studies, x='similarity', nbins=20, title="Similarity Distribution")

        # Actionable insights
        avg_sample_size_success = df[df['outcome'] == 'Success']['sample_size'].mean()
        insights = []
        if sample_size < avg_sample_size_success:
            insights.append(f"Sample size ({sample_size}) is below average for successful studies ({int(avg_sample_size_success)}). Consider increasing.")

        return render_template('index.html',
                               failure_prob=round(failure_prob, 2),
                               pie_chart=json.dumps(pie_fig, cls=plotly.utils.PlotlyJSONEncoder),
                               hist_chart=json.dumps(hist_fig, cls=plotly.utils.PlotlyJSONEncoder),
                               insights=insights,
                               similar_studies=similar_studies[['therapeutic_area', 'phase', 'sample_size', 'outcome', 'failure_reason']].to_dict('records'))

    return render_template('index.html')

if __name__ == '__main__':
    init_db()
    generate_data()