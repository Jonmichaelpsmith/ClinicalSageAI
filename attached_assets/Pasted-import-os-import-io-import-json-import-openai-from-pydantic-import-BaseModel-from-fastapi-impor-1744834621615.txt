import os
import io
import json
import openai
from pydantic import BaseModel
from fastapi import APIRouter, HTTPException, Body, Response
from ingestion.fda_faers import get_faers_cached
from ingestion.normalize import normalize_faers, normalize_mauDe, normalize_eudamed
from ingestion.fda_device import get_device_complaints
from ingestion.eu_eudamed import fetch_eudamed_data
from predictive_analytics import aggregate_time_series, forecast_adverse_events, detect_anomalies
from redis import Redis
from reportlab.lib.pagesizes import letter, landscape
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors

# Ensure OPENAI API key
env_key = "OPENAI_API_KEY"
if not os.getenv(env_key):
    raise RuntimeError(f"Environment variable {env_key} must be set")
openai.api_key = os.getenv(env_key)

# Redis cache client
ttl_seconds = 3600  # 1 hour caching
token = os.getenv("REDIS_URL") or "redis://localhost:6379/0"
redis_client = Redis.from_url(token)

# Utility: generate cache key
def _cache_key(prefix: str, identifier: str):
    return f"cer_narrative:{prefix}:{identifier}"

# Analysis builders
def build_faers_analysis(ndc_code: str, periods: int = 3) -> dict:
    raw = get_faers_cached(ndc_code)
    normalized = normalize_faers(raw, ndc_code)
    series = aggregate_time_series(normalized)
    forecast = forecast_adverse_events(series, periods=periods)
    anomalies = detect_anomalies(series)
    total = sum(rec.get("count", 0) for rec in normalized)
    return {
        "product_code": ndc_code,
        "source": "FAERS",
        "total_count": total,
        "trend": {str(idx.date()): int(val) for idx, val in series.items()},
        "forecast": forecast,
        "anomalies": anomalies
    }

def build_device_analysis(device_code: str, periods: int = 3) -> dict:
    raw = get_device_complaints(device_code)
    normalized = normalize_mauDe(raw, device_code)
    series = aggregate_time_series(normalized)
    forecast = forecast_adverse_events(series, periods=periods)
    anomalies = detect_anomalies(series)
    total = sum(rec.get("count", 0) for rec in normalized)
    return {
        "product_code": device_code,
        "source": "MAUDE",
        "total_count": total,
        "trend": {str(idx.date()): int(val) for idx, val in series.items()},
        "forecast": forecast,
        "anomalies": anomalies
    }

def build_multi_analysis(ndc_codes: list[str] = None, device_codes: list[str] = None, periods: int = 3) -> dict:
    analyses = []
    if ndc_codes:
        for ndc in ndc_codes:
            analyses.append(build_faers_analysis(ndc, periods))
    if device_codes:
        for dev in device_codes:
            analyses.append(build_device_analysis(dev, periods))
    if device_codes:
        for dev in device_codes:
            stub = fetch_eudamed_data(dev)
            eu_norm = normalize_eudamed(stub)
            analyses.append({
                "product_code": dev,
                "source": "Eudamed",
                "records": eu_norm
            })
    return {"analyses": analyses}

# Prompt builder
def _generate_prompt(analysis_data: dict) -> str:
    parts = []
    for item in analysis_data.get('analyses', []):
        src, code = item.get('source'), item.get('product_code')
        if src in ["FAERS", "MAUDE"]:
            parts.append(
                f"Source: {src}, Code: {code}, Total: {item['total_count']}, "
                f"Trend: {item['trend']}, Forecast: {item['forecast']}, Anomalies: {item['anomalies']}"
            )
        else:
            parts.append(f"Source: {src}, Code: {code}, Info: {item.get('records')}")
    return (
        "You are a regulatory-compliant CER generator. Based on the following multi-source analysis data, "
        "generate a cohesive Clinical Evaluation Report narrative including an executive summary, trends, forecasts, "
        "anomaly analysis, and benefit-risk considerations.\n\n" + "\n".join(parts)
    )

# Cache fetch/generate helper
def _fetch_or_generate(prefix: str, identifier: str, generator_fn) -> str:
    key = _cache_key(prefix, identifier)
    cached = redis_client.get(key)
    if cached:
        return cached.decode('utf-8')
    narrative = generator_fn()
    redis_client.setex(key, ttl_seconds, narrative)
    return narrative

# PDF builder
def _build_pdf(narrative: str, title: str) -> bytes:
    buf = io.BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=landscape(letter))
    styles = getSampleStyleSheet()
    elems = [Paragraph(title, styles['Title']), Spacer(1, 12), Paragraph(narrative, styles['BodyText'])]
    doc.build(elems)
    buf.seek(0)
    return buf.getvalue()

# FastAPI router
router = APIRouter(prefix="/api/narrative", tags=["narrative"])

@router.get("/faers/{ndc_code}")
async def narrative_faers(ndc_code: str, periods: int = 3):
    try:
        id = f"faers:{ndc_code}:{periods}"
        def gen(): return openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[{"role":"user","content":_generate_prompt({"analyses":[build_faers_analysis(ndc_code,periods)]})}],
            temperature=0.2, max_tokens=800
        ).choices[0].message.content.strip()
        narrative = _fetch_or_generate('faers', id, gen)
        return {"product_code": ndc_code, "source": "FAERS", "narrative": narrative}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"FAERS narrative failed: {e}")

@router.get("/faers/{ndc_code}/pdf")
async def narrative_faers_pdf(ndc_code: str, periods: int = 3):
    try:
        data = await narrative_faers(ndc_code, periods)
        pdf_bytes = _build_pdf(data['narrative'], f"FAERS CER: {ndc_code}")
        return Response(content=pdf_bytes, media_type="application/pdf")
    except HTTPException as he:
        raise he
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"FAERS PDF failed: {e}")

@router.get("/device/{device_code}")
async def narrative_device(device_code: str, periods: int = 3):
    try:
        id = f"device:{device_code}:{periods}"
        def gen(): return openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[{"role":"user","content":_generate_prompt({"analyses":[build_device_analysis(device_code,periods)]})}],
            temperature=0.2, max_tokens=800
        ).choices[0].message.content.strip()
        narrative = _fetch_or_generate('device', id, gen)
        return {"product_code": device_code, "source": "MAUDE", "narrative": narrative}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Device narrative failed: {e}")

@router.get("/device/{device_code}/pdf")
async def narrative_device_pdf(device_code: str, periods: int = 3):
    try:
        data = await narrative_device(device_code, periods)
        pdf_bytes = _build_pdf(data['narrative'], f"Device CER: {device_code}")
        return Response(content=pdf_bytes, media_type="application/pdf")
    except HTTPException as he:
        raise he
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Device PDF failed: {e}")

class MultiRequest(BaseModel):
    ndc_codes: list[str] | None = None
    device_codes: list[str] | None = None
    periods: int = 3

@router.post("/multi")
async def narrative_multi(request: MultiRequest = Body(...)):
    try:
        id = f"multi:{','.join(request.ndc_codes or [])}:{','.join(request.device_codes or [])}:{request.periods}"
        def gen(): return openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[{"role":"user","content":_generate_prompt(build_multi_analysis(
                ndc_codes=request.ndc_codes, device_codes=request.device_codes, periods=request.periods))}],
            temperature=0.2, max_tokens=800
        ).choices[0].message.content.strip()
        narrative = _fetch_or_generate('multi', id, gen)
        return {"narrative": narrative, "analysis": build_multi_analysis(
            ndc_codes=request.ndc_codes, device_codes=request.device_codes, periods=request.periods)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Multi-source narrative failed: {e}")

@router.post("/multi/pdf")
async def narrative_multi_pdf(request: MultiRequest = Body(...)):
    try:
        resp = await narrative_multi(request)
        pdf_bytes = _build_pdf(resp['narrative'], "Multi-Source CER")
        return Response(content=pdf_bytes, media_type="application/pdf")
    except HTTPException as he:
        raise he
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Multi PDF failed: {e}")
