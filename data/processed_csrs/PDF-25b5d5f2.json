{
  "nctrialId": "PDF-25b5d5f2",
  "csr_id": "PDF-25b5d5f2",
  "title": "1. Learning Objectives",
  "officialTitle": "1. Learning Objectives",
  "sponsor": "pharmaceutical or biotechnology companies",
  "indication": "Cancer",
  "phase": "Phase 1",
  "fileName": "Clinical-Trials.pdf",
  "fileSize": 1302786,
  "date": "2025-04-14",
  "completionDate": "2025-04-14",
  "drugName": "",
  "source": "PDF Document: Clinical-Trials.pdf",
  "studyType": "Interventional",
  "status": "Completed",
  "description": "1. Learning Objectives  After reviewing this chapter readers should be able to:  Identify and classify different types of trial designs when reading a trial report;  \u2022  Understand the essential design issues of randomized clinical trials;  \u2022  Appreciate three possible sources of errors that could le...",
  "eligibilityCriteria": "No eligibility criteria extracted from document.",
  "full_text": "Clinical Trials \n\n1. Learning Objectives \n\nAfter reviewing this chapter readers should be able to: \n\n\u2022 \n\nIdentify and classify different types of trial designs when reading a trial report; \n\n\u2022  Understand the essential design issues of randomized clinical trials; \n\n\u2022  Appreciate three possible sources of errors that could lead to erroneous trial results;  \n\n\u2022  Understand the basic statistical principles, concepts, and methods for clinical data \n\nanalysis and reporting; and \n\n\u2022  Understand some frequently used terms in clinical trials. \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f2. Introduction \n\nRandomized clinical trials are scientific investigations that examine and evaluate the safety and \n\nefficacy of new drugs, devices, tests, or lifestyle interventions using human subjects. \n\nThe primary aim of most clinical trials is to provide an unbiased \n\nevaluation of the merits of using one or more treatment options for a \n\ngiven disease or condition of interest. \n\nThe results that these clinical trials generate are considered to be the most robust data in the \n\nera of evidence-based medicine. Ideally, clinical trials should be performed in a way that isolates \n\nthe effect of treatment on the study outcome and provides results that are free from study bias. \n\nA common approach by which to achieve this aim is through randomization, whereby patients \n\nare assigned to a treatment group by random selection. Patients and trial personnel are \n\ndeliberately kept unaware of which patient is on the new drug. This minimizes bias in the later \n\nevaluation so that the initial blind random allocation of patients to one or other treatment group \n\nis preserved throughout the trial. \n\nClinical trials must be designed in an ethical manner so that patients are not denied the benefit \n\nof usual treatments. Patients must give their voluntary consent that they appreciate the purpose \n\nof the trial. Several key guidelines regarding the ethics, conduct, and reporting of clinical trials \n\nhave been constructed to ensure that a patient\u2019s rights and safety are not compromised by \n\nparticipating in clinical trials (Declaration of Helsinki, 2005; Altman et al., 2001). \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f Exercise 1: Importance of Clinical Trials \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f2. Introduction \n\nA large proportion of clinical trials are sponsored by pharmaceutical or biotechnology companies \n\nthat are developing a new disease management intervention: drug, device, or diagnostic \n\nstrategy. Disease specific charities may also fund investigators to conduct studies and large \n\ncentral government bodies interested in health care will also sponsor scientifically valid studies. \n\nClinical trials usually involve a program of studies from initial exploratory studies on a handful of \n\nsubjects to large trials involving hundreds or thousands of subjects, requiring considerable \n\nfinancial investment usually into the millions of dollars over several years. Given this \n\ninvestment, there is often an expectation of a return from this investment. The more \n\ncommercial the source of funding, the greater the expectation for financial success and the \n\ngreater the pressure on those involved to produce positive results. In the last 20 years however, \n\nresearchers have recognized the need to disconnect funding from the design and conduct of \n\ntrials and many pharmaceutical companies now employ independent research organizations to \n\nundertake such studies. \n\nImportant clinical questions without immediate apparent commercial \n\nvalue but improving the delivery of care to patients or studies using \n\nolder drugs in new disease areas will often be funded by health-related \n\ngovernment agencies, or through charitable grants. \n\n \n \n                                                                                                 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f3. Classification \n\nClinical trials vary depending on who initiates the trial: \n\n\u2022  Clinicians; \n\n\u2022  Pharmaceutical or other health care companies; \n\n\u2022  Government bodies; or \n\n\u2022  Health providers, who may all initiate trials depending on their interest. \n\nTypically pharmaceutical \n\ncompanies conduct trials involving \n\nnew drugs or established drugs in \n\ndisease areas where their drug \n\nmay gain a new license. \n\nDevice manufacturers use trials to \n\nprove the safety and efficacy of \n\ntheir new device. Clinical trials \n\ninitiated by clinical investigators \n\nmay ask questions of when or how \n\nbest to administer a specific \n\ntherapy or when to withdraw a \n\ntherapy and they may use \n\nestablished or older drugs with \n\nlittle commercial value in new \n\ndisease areas. \n\nGovernment bodies or health care \n\nproviders may trial vaccines or best \n\nways of organizing care delivery (e. \n\ng., availability of contraception \n\nmethods or uptake of the measles \n\nvaccine). \n\nAppropriate uses of clinical trials \n\nA clinical trial is appropriate to evaluate \n\nwhich is the most cost effective drug \n\nchoice. Clinical trials are also appropriate \n\nfor evaluating whether a new device \n\nachieves a certain goal as effectively and \n\nsafely as standard devices. \n\nHowever, investigating the causes of \n\nParkinson's disease, for example, is better \n\nsuited by a cohort study or case-control \n\nstudy because cohort studies are able to \n\nobserve groups to determine frequency of \n\nnew incidence of disease and case-control \n\nstudies observe patients with diseases to \n\nbetter understand disease characteristics. \n\n \n \n                \n \n \n \n \n \n \n \n\f Exercise 2: Reasons for Clinical Trials \n\n \n \n                \n \n \n \n \n \n \n\f3. Classification \n\nPhases \n\nFor commercial purposes, trials have been classified into various phases, determined by the \n\npharmaceutical industry based on the four phases of development of a particular drug (Phases \n\nI\u2013IV) (Chow & Liu, 1998). \n\n Figure 1: Basic Trial Designs \n\nPHASES \n\nPhase I - Test Drug in Healthy Volunteers \n\nTest the effects of a new therapeutic agent in healthy volunteers following successful animal \n\nstudies. These examine how the drug is handled in the human body (pharmacokinetics/ \n\npharmacodynamics), particularly with respect to immediate short-term safety of higher \n\ndoses. \n\nPhase II - Test drug in Patients with the Disease \n\nExamine dose\u2013response curves in patients using different dosages of the therapeutic agent \n\nin usually a small group of patients with a particular disease. \n\nPhase III - Test Drug Against Placebo \n\nA new drug is tested in a controlled fashion in a large patient population against a placebo \n\nor standard therapy. This is a key phase, where a drug must establish superior or \n\nequivalent efficacy to standard therapy or placebo. A positive study in Phase III is often \n\n \n \n                \n \n \n\fknown as a landmark study. \n\nPhase IV - Test Drug While in the Marketplace \n\nA postmarketing study as the drug has already been granted regulatory approval/license. \n\nThese later studies are crucial for gathering additional safety information from a larger \n\ngroup of patients with respect to the long-term safety of the drug or for establishing a drug \n\nin a new or wider group of patients. \n\n \n \n                                                  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f3. Classification \n\nTrial design \n\nTrials can be further classified by design. This classification is more descriptive in terms of how \n\npatients are randomized to treatment. \n\nParallel-Group trials are the most common design (Pocock, 1983; Friedman, 1998). Patients are \n\nrandomized to the new treatment or the standard treatment and followed-up to determine the \n\neffect of each treatment in parallel groups. \n\nCrossover trials randomize patients to different sequences of treatments, but all patients \n\neventually get all treatments in varying order, i.e., the patient is his/her own control (Senn, \n\n2002; Jones & Kenward, 2003; Wang et al., 2006g). \n\nFactorial trials assign patients to more than one treatment-comparison group that are \n\nrandomized in one trial at the same time; i.e., while drug A is being tested against placebo, \n\npatients are re-randomized to drug B or placebo, making four possible treatment combinations \n\nin total (Fox et al., 2006). \n\nCluster randomized trials are performed when larger groups (e.g., patients of a single \n\npractitioner or hospital) are randomized instead of individual patients (Mallick et al., 2006b). \n\nCluster trials can be any of the previously mentioned designs. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f Figure 2: Basic Trial Designs \n\n \n                                                                                                        \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f3. Classification \n\nNumber of centers \n\nClinical trials can also be classified as single-center or multicenter studies according to the \n\nnumber of sites involved. While single-site studies are mainly used for Phase I and II studies, \n\nmulticenter studies can be carried out at any stage of clinical development. \n\nMulticenter studies are necessary for two major reasons (Truesdale et al., 2006; Matthews, \n\n2000): \n\n\u2022  To evaluate a new medication or procedure more efficiently in terms of accruing \n\nsufficient subjects over a shorter period of time; and \n\n\u2022  To provide a better basis for the subsequent generalization of the trial\u2019s findings, i.e., \n\nthe effects of the treatment are likely to be similar in a wider setting across centers \n\nnot involved in the trial. \n\nOther classifications \n\nTrials can also be described as superiority studies, equivalence studies, or noninferiority studies \n\nin terms of what the study was designed to prove. \n\n\u2022  A superiority study aims to show that a new drug is more effective than the \n\ncomparative treatment (placebo or current best treatment) (Pocock, 1983; Chow et \n\nal., 2003). Most clinical trials belong to this category. \n\n\u2022  On the other hand, an equivalence trial is designed to prove that two drugs have the \n\nsame clinical benefit. Hence, the trial should demonstrate that the effect of the new \n\ndrug differs from the effect of the current treatment by a margin that is clinically \n\nunimportant (Bakhai et al., 2006c; Wang et al., 2006a). \n\n\u2022  A noninferiority trial aims to show that the effect of a new treatment cannot be said to \n\nbe significantly weaker than that of the current treatment. \n\nIn the latter two trials the new treatment might still turn out to be more effective than the \n\ncomparative treatment, but this is not the prior assumption of the trial (Miller et al., 2006). \n\n \n \n                \n \n \n \n \n \n \n\f Exercise 3: Patient Study Design \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f3. Classification \n\nClinical trials can also be classified by whether the trial is: \n\n\u2022  The first to compare a specific treatment (exploratory); or \n\n\u2022  A further trial trying to confirm a previous observation (confirmatory) (Day, 1999).  \n\nAn exploratory study might also seek to identify key issues rather than to confirm or challenge \n\nexisting results regarding the treatment effect. For example, it might look at the impact of a \n\nnew drug in a specific subset of patients who have additional diseases to the main disease of \n\ninterest, such as diabetic patients with heart disease. On occasions, a study can have both \n\nconfirmatory and exploratory aspects. For instance, in a confirmatory trial evaluating a specific \n\ntreatment, the data can also be used to explore further hypotheses, i.e., subgroup effects that \n\nhave to be confirmed by later research. \n\n Exercise 4: Study Design Descriptions \n\n \n \n                \n \n \n \n \n \n \n \n\f4. Endpoints \n\nEndpoints \n\nA clinical trial endpoint is defined as a measure that allows us to decide whether the null \n\nhypothesis of a clinical trial should be accepted or rejected (Bakhai et al., 2006a). In a clinical \n\ntrial, the null hypothesis states that there is no statistically significant difference between two \n\ntreatments or strategies being compared with respect to the endpoint measure chosen. \n\nClinical trial endpoints can be classified as primary or secondary. \n\nPrimary endpoints measure outcomes that will answer the primary (or most important) question \n\nbeing asked by a trial, such as whether a new treatment is better at preventing disease-related \n\ndeath than the standard therapy. In this case, the primary endpoint would be based on the \n\noccurrence of disease-related deaths during the duration of the trial. The size of a trial is \n\ndetermined by the power needed to detect a difference in this primary endpoint. \n\nSecondary endpoints ask other relevant questions about the same study; for example, whether \n\nthere is also a reduction in disease measures other than death, or whether the new treatment \n\nreduces the overall cost of treating patients. When secondary endpoints are also important the \n\ntrial must be powered sufficiently to detect a difference in both endpoints, and expert statistical \n\nand design advice may be needed. \n\nTypes of Endpoints \n\nAn endpoint could take different forms: \n\n\u2022  A quantitative (or continuous or numerical) measurement representing a specific \n\nmeasure or count (e.g., quality of life, blood pressure, or heart rate). These endpoints \n\ncan be summarized by means and medians (Wang et al., 2006f). \n\n\u2022  A binary clinical outcome indicating whether an event has occurred (e.g., death from \n\nany cause, the occurrence of disease signs or symptoms, the relief of symptoms). The \n\nproportions, odds ratios and risk ratios can be used to compare these endpoints \n\n(Wang et al., 2006d). \n\n \n \n                \n \n \n \n \n \n \n \n\f\u2022  The time to occurrence of an event of interest or survival time (e.g., the time from \n\nrandomization of patient to death). Kaplan-Meier plot is often used to compare the \n\nsurvival experience graphically and Cox model is frequently used to estimate the \n\ntreatment effect (Cox, 1984; Wang et al., 2006b). \n\n\u2022  The use of healthcare resources (e.g. the number of hospital admissions). \n\nIdeally, a trial should have a single endpoint based on just one \n\noutcome measure. However, as the art of trial design has evolved, \n\nmost large trials have a primary (composite) endpoint consisting of \n\nmultiple outcome measures. An endpoint can also be the time taken for \n\nan event to occur. For such an endpoint, the events of interest for \n\nwhich a time is to be recorded\u2014such as stroke or heart attack\u2014must \n\nbe predefined. Trial endpoints can also be a quantitative measurement \n\nof a biochemical or socioeconomic parameter such as cholesterol level \n\nor quality-of-life. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f4. Endpoints \n\nComposite Endpoints \n\nWhile some guidelines\u2014such as the guidance on trial design in the International Conference on \n\nHarmonization Guideline for Good Clinical Practice \u2014generally prefer a primary endpoint based \n\non a single outcome that will be defined before the study begins, many recent studies include \n\nmultiple outcomes as part of a composite endpoint. Exploratory clinical investigations or early-\n\nphase studies are more likely to have multiple outcomes, with some of these being developed \n\nduring the study. \n\nAn example of a clinical trial with a composite endpoint of multiple \n\noutcomes is the CURE (Clopidogrel in Unstable Angina to Prevent \n\nRecurrent Events) study (Yusuf, Zhao, Mehta et al., 2001). This study \n\nlooked at the effects of clopidogrel in patients with acute coronary \n\nsyndromes without ST-segment elevation. In this trial, the primary \n\nendpoint was a composite of the following clinical outcomes: \n\n\u2022  Death from cardiovascular causes; \n\n\u2022  Stroke; and \n\n\u2022  Nonfatal myocardial infarction. \n\nWhen multiple outcomes can be experienced by any of the patients it is often best to present \n\nboth the total number of outcomes per patient and hierarchical counts of outcomes. In the \n\nlatter, only one outcome can be counted for each patient, and it is usually the most serious \n\noutcome that is recorded. The rules for the hierarchy of outcomes are usually established in \n\nadvance of the trial, with a fatal outcome taking precedence over a nonfatal one. Another way of \n\ncombining outcomes would be to compare the number of recurrences of identical outcomes, \n\nsuch as the number of seizures experienced by patients with epilepsy during a follow-up period. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f Exercise 5: Not a Trial Endpoint \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f5. Design Issues \n\nPatient Selection \n\nThe aim of a clinical trial is sometimes to investigate the efficacy of an intervention in patients \n\nwith a particular disease or condition. When performing a trial, it is impossible to enroll every \n\npatient with the particular disease or condition \u2013 instead, a sample of patients is selected that \n\nrepresents the population of interest. Essentially, the findings from the trial should have \n\nrelevance to patients in future clinical practice, i.e., the study should have external validity or \n\ngeneralizability. \n\nIn order to ensure generalizability: \n\n\u2022 \n\nIt is essential to have an understanding of \n\nthe disease and its current treatment \n\noptions. \n\n\u2022  The selected sample must truly reflect the \n\npopulation it represents, and the eligibility \n\ncriteria must not be so restrictive that they \n\nhamper recruitment or limit the \n\ngeneralizability of the findings. \n\nHowever, eligibility criteria also serve the function of \n\nchoosing a sample who can tolerate being in a trial \n\nand those in whom there are less co-morbidities that \n\nmight dilute the effect of the intervention. \n\nSome of the basic \n\nconsiderations for design \n\nin clinical trials are: \n\n\u2022  Patient \n\nselection \n\n\u2022  Protocol \n\n\u2022  Randomization \n\n\u2022  Blinding \n\n\u2022  Sample size \n\ndetermination \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f Exercise 6: Lowering Blood Pressure Trial \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n\f5. Design Issues \n\nProtocol \n\nThe trial protocol is a formal document that specifies how a clinical trial is to be conducted. It \n\ndescribes the: \n\n\u2022  Objective(s); \n\n\u2022  Design; \n\n\u2022  Methodology; \n\n\u2022  Statistical considerations; and \n\n\u2022  Administrative structure of the trial (Mallick et al., 2006a; ICH, 2005). \n\nWe can also regard the protocol as a scientific, administrative, and organizational project \n\nguideline that may be the basis of a contractual relationship between an investigator and a trial \n\nsponsor. \n\nWell-designed protocols are important for conducting clinical trials \n\nsafely and in a cost-effective manner. \n\nDifferent trial protocols will retain very similar key components. However, adaptations may be \n\nnecessary for each trial\u2019s particular circumstances. \n\nIn scientific research, the first step is to set up a hypothesis, and then to construct an \n\nappropriate study design to test that hypothesis. In clinical trials, the hypothesis is usually \n\nrelated to one form of therapeutic intervention that is expected to be superior or equal to \n\nanother in terms of specific outcomes. Once this hypothesis is developed, the study\u2019s aims, \n\ndesign, methodology, statistical methods, and analyses should be formulated. \n\nThe protocol should clearly address issues related to: \n\n\u2022  The study\u2019s conduct; \n\n\u2022  Set up; \n\n\u2022  Organization; \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n\f\u2022  Monitoring; \n\n\u2022  Administrative responsibilities; \n\n\u2022  Publication policy; and \n\n\u2022  Timelines in appropriate sections. \n\nTrial guidelines and regulatory requirements, such as the International \n\nConference on Harmonization guidelines for Good Clinical Practice \n\n(ICH\u2013GCP, 2005), the Declaration of Helsinki (Declaration of Helsinki, \n\n2005), the EU Clinical Trials Directive (EUCTD, 2001), and the US Food \n\nand Drug Administration (FDA) Regulations Relating to Good Clinical \n\nPractice and Clinical Trials (FDA, 2005), should be followed as \n\nappropriate. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f5. Design Issues \n\nRandomization \n\nWhy should patients in a clinical trial be randomized? The randomized controlled trial (RCT) is \n\nconsidered the gold standard for testing the efficacy of medical treatments (Pocock, 1983). \n\nA fundamental assumption that forms the basis of the RCT is that \n\npatients in different groups are similar for characteristics such as age, \n\ngender, social class, time of year of presentation, country of \n\npresentation, and type of hospital. \n\nThis assumption is the basis of all comparative statistical tests performed in the trial. To achieve \n\nthis balance we randomly assign the patients (hence the term randomized in an RCT) to each \n\ntreatment strategy so that, for example, men have an equal chance of being given treatment A \n\nor B, people aged over 60 years have an equal chance of being given treatment A or B, and so \n\non. Simple randomization is one way of performing this balancing function, but other methods \n\nare needed when the number of patients is small. \n\nMinimizing bias \n\nA further requirement of randomization is that it must not be predictable by the person \n\nassigning patients to the treatment strategies; otherwise there is a chance that the groups will \n\ncontain bias. To prevent this, certain methods of blinding or masking are used so that patients \n\nand staff (with the usual exception of the data and safety monitoring board) are not aware \n\nwhether treatment A or B is the new treatment, or even which group patients are in (active or \n\nplacebo/standard treatment), until the end of the trial. Physicians and study coordinators \n\nproviding the treatments to the patients use a randomization code to find out which treatment \n\npack has been assigned to each patient (A or B), but the code provides no information about \n\nwhich treatment is which (active or placebo/standard treatment). Randomization must be \n\nprotected by blinding so that it remains unpredictable. \n\nDetermining randomization codes \n\n \n \n                \n \n \n \n \n \n \n \n \n \n\fA randomization code is a list of which treatment a subject should receive. It is usually \n\ndetermined by a statistician using computer-generated random numbers or a random-number \n\ntable. \n\nSome trials use methods for assigning subjects according to: \n\n\u2022  Date of birth (odd or even years); \n\n\u2022  Hospital record number; or \n\n\u2022  Date of screening for the study (odd or even days). \n\nHowever, these randomization methods have a level of predictability, so strictly speaking they \n\nare not acceptable methods of randomization. \n\nCommon randomization methods \n\nThe generation of a randomization code can be achieved using one of a variety of procedures. \n\nOnce a code and method of allocation are decided on, their rules must be adhered to throughout \n\nthe study. \n\nCommon types of randomization methods are (Wang & Bakhai, 2006a): \n\n\u2022  Simple randomization; \n\n\u2022  Block randomization; \n\n\u2022  Stratified randomization; or \n\n\u2022  Minimization or adaptive randomization. \n\nA combination of these methods can also be used, and other special methods have also been \n\nused (Chow & Liu, 1998). \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f5. Design Issues \n\nBlinding \n\nRandomization can minimize the influence of bias in clinical trials by balancing groups for \n\nvarious characteristics. Bias can still occur, however, if study personnel and patients know the \n\nidentity of the treatment, due to preconceptions and subjective judgment in reporting, \n\nevaluation, data processing, and statistical analysis. To minimize these biases, studies should be \n\nblinded, or masked, so that all participants are unaware of whether the subjects are assigned to \n\nthe new or standard therapy during a trial. \n\nThere are four general types of blinded studies in clinical trials (Bakhai \n\net al., 2006b): \n\n\u2022  Open/unblinded; \n\n\u2022  Single blinded; \n\n\u2022  Double blinded; and \n\n\u2022  Triple blinded. \n\nOpen / Unblinded Studies \n\nOn some occasions it might not be possible to use blinding. For example, if the new intervention \n\nis a surgical treatment and is being compared with tablets then the difference between the two \n\nis difficult to hide. Such studies might need to be unblinded as far as the patients and caregivers \n\nare concerned, and are known as open or unblinded studies. The main problem with this type is \n\nthat patients may underreport adverse effects of the new treatment. \n\nSingle-Blinded Studies \n\nIn single-blinded studies, the patient should be unaware of which treatment they are taking, \n\nwhile the investigators are aware of whether the treatment is new, standard, or placebo. The \n\ndisadvantage is that patients might under- or over-report treatment effects and side-effects, \n\nbased on some influence or response from the investigators. Investigators may give advice or \n\nprescribe additional therapy to the control group if they feel that these patients are \n\ndisadvantaged in comparison to the active group, and so a number of subtle biases could be \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n\fintroduced either in favor of or against the new treatment depending on the investigators\u2019 \n\nopinions. \n\nDouble-Blinded Studies \n\nIn double-blinded studies, neither the patient nor the investigator knows the identity of the \n\nassigned intervention (Chow & Liu, 1998). A number of biases are thus reduced, such as \n\ninvestigators\u2019 preconceptions of the treatments used in the study. This reduces the ability of the \n\ninvestigators to monitor the safety of treatments, so a Data Safety Monitoring Committee \n\n(DSMC) must regularly review the rate of adverse events in each arm of the trial. \n\nOperating these committees is difficult, as they must meet regularly enough to be able to detect \n\ndifferences promptly, avoiding needless further harm to patients, while avoiding early \n\ntermination of a trial due to a chance difference. \n\nTriple-Blinded Studies \n\nIn triple-blinded studies, in addition to the investigators and participants, all members of the \n\nsponsor\u2019s project team (e.g., the project clinician, statistician, and data manager), and even the \n\nDSMC are blinded (Chow & Liu, 1998). This lessens the chance that the DSMC will stop the trial \n\nearly in favor of either treatment, and makes evaluations of the results more objective. \n\nHowever, this hampers the DSMC\u2019s ability to monitor safety and efficacy endpoints, and some \n\ninvestigators might feel uncomfortable when participating because there is no one to oversee \n\nthe results as they accrue. Triple blinding is appropriate for studies in which the risk of adverse \n\nevents due to the new or standard treatment is low, and should not be used for treatments \n\nwhere safety is a critical issue. Due to the reduced ability of the DSMC to see trends early, \n\nrecruitment might need to continue until statistical significance is reached for either clinical \n\neffects or adverse events. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n\f5. Design Issues \n\n Exercise 7: Blinding Methods \n\n \n \n                \n \n \n \n\f5. Design Issues \n\nSample Size Determination \n\nWhat is the sample size for a randomized clinical trial? \n\nThe sample size of a randomized controlled trial is the number of subjects that are to be \n\nenrolled in the study (Wang & Bakhai, 2006b; Chow at al., 2007). Choosing the right sample \n\nsize is critical for a study, and is based on two key assumptions: \n\n\u2022  The size of the benefit we anticipate with the new treatment compared to \n\nstandard (or placebo) treatment (the \u2018expected treatment effect\u2019); and \n\n\u2022  The amount of certainty we wish to have with which to capture the treatment \n\nbenefit (the \u2018power\u2019 of the study). \n\nThe larger the sample size, the better the power with which to detect a treatment effect, which \n\nmeans that smaller treatment effects can be detected as statistically significant. In the same \n\nway, the smaller the sample size, the less power we have with which to detect a treatment \n\neffect, meaning that the effect must be greater in order to be detected as significant. The \n\ncalculation used to find the required sample size for a trial is also influenced by the trial\u2019s \n\ndesign, so the method by which the primary outcome is to be determined must also be clarified \n\nin advance of determining the sample size. \n\nWhy do we have to choose a sample size? \n\nWhen resources are limited we must decide how best to invest those in order to maximize the \n\nbenefits received. For example, should we use treatment X or treatment Y? To answer this \n\nquestion, we need to decide how hard we will look for the answer. Until we do, people will \n\ncontinue to be given or refused a treatment without evidence. We might decide that it is only \n\nworth looking at the question if we are fairly likely to detect a 10% improvement with the new \n\ntreatment. To improve the chance that such a difference is detected (if it exists) we have to \n\nchoose the sample size wisely, based on realistic initial assumptions. More importantly, it is \n\nunethical to carry out a study that is unlikely to capture a real difference since we will have \n\nspent precious resources on performing a study for no gain. From this, we can appreciate that \n\n \n \n                \n \n \n \n \n \n \n\fchoosing an appropriate sample size for a study is dependent on good judgment, which is critical \n\nto a trial\u2019s success. \n\nAre negative trials due to small sample sizes? \n\nA negative clinical trial is a trial in which the observed differences between the new and \n\nstandard treatments are not large enough to satisfy a specified significance level (Type I error \n\nthreshold), so the results are declared to be not statistically significant (Wang et al., 2006e). \n\nWith the benefit of hindsight, analyses of negative clinical trials have shown that the \n\nassumptions chosen by investigators often lead them to choose a sample size that is too small \n\nto offer a reasonable chance of avoiding a false-negative error (a Type II error). \n\nNot all negative trials are due to insufficient power. In some cases it might be that the event \n\nrate in the control group was lower than expected or that there were confounding factors, such \n\nas changes to routine treatment methods during the duration of the study. A branch of medical \n\nstatistics known as meta-analysis combines the results from many such small studies to try to \n\nestimate a true mean effect more closely. If this analysis shows that the new treatment has a \n\nfavorable benefit, then this should be verified by performing a larger, definitive RCT. However, \n\none must always take into consideration the outlay of resources required to realize the potential \n\nbenefit, and even then, large RCTs might produce unexpected results. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f6. Erroneous Trial Results \n\nIn a clinical trial, the observed treatment effect regarding the safety and efficacy of a new drug \n\nmay represent the \u2018true\u2019 difference between the new drug and the comparative treatment or it \n\nmay not. This is to say that if the trial were to be repeated with all the available patients in the \n\nworld then the outcome would either be the same as the trial (a true result) or different (making \n\nthe trial result a chance event, or an erroneous false result). Understanding the possible sources \n\nof erroneous results is critical in the appreciation of clinical trials. \n\nReasons for erroneous results fall into three main categories. \n\n\u2022  The trial may have been biased in some predictable fashion. \n\n\u2022  It could have been contaminated (confounded) by an \n\nunpredictable factor. \n\n\u2022  The result may simply have occurred by random chance. \n\n Example 1: Potential Biases \n\nA cinnamon-based herbal oil reduced breast pain in women compared to evening primrose \n\noil. Commercial oils were used for the study. The new cinnamon oil was provided free to all \n\nparticipants, while the primrose oil needed a prescription to be filled by the patient. \n\nIn this example, there are several sources of potential bias, including: \n\n\u2022  Trial not blinded; \n\n\u2022  New medications are appealing; \n\n\u2022  False safety impression; \n\n\u2022 \n\nImpressions based on age; \n\n\u2022  Patient drop out; and \n\n\u2022  Self-fulfilling prophecy. \n\nThe first source is not blinding the trial. This could result in bias because if the trial is not \n\nblinded, it is easy to know which oil women were on, resulting in observer bias and volunteer \n\nbias in terms of recording and reporting breast pain. New medications can be a source of bias \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n\fbecause they are appealing and they usually attract positive attitudes from patients and, more \n\nimportantly, physicians, especially those in a trial. This is often referred to as observer\u2019s bias. \n\nSide effects of newer medications are not as extensively known or documented often giving a \n\nfalse impression of safety. This can be referred to as information bias. Impressions based on \n\nage can be a source of bias because younger, healthier patients are more likely to participate in \n\nthe study and appreciate new products rather than the skepticism of new products that is often \n\nfound in older patients. This is an example of selection bias. A confounding treatment effect \n\ncan be caused by imbalances in subject distribution by treatment group. Non-blinded studies \n\nmay not have balanced groups if people drop out if chosen for the prescription therapy arm. \n\nAnother source is known as the self fulfilling prophecy effect. This is when physicians \n\nthemselves may influence patients if they know which therapy a patient is receiving and may \n\ncapture or record patient experiences during the trial with their own \u201cpre-judgement\u201d biases. \n\nThis is also an example of observer\u2019s bias. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f6. Erroneous Trial Results \n\nBias/systematic errors \n\nBias can influence a trial by the occurrence of systematic errors that are associated with the \n\ndesign, conduct, analysis, and reporting of the results of a clinical trial. Bias can also make the \n\ntrial-derived estimate of a treatment effect deviate from its true value (Arezina & Wang, 2006; \n\nChow & Liu, 1998; Jadad, 1998). The most common types of bias in clinical trials are those \n\nrelated to subject selection and outcome measurement. For example, if the investigator is aware \n\nof which treatment a patient is receiving, it could affect the way he/she collects information on \n\nthe outcome during the trial or he/she might recruit patients in a way that could favor the new \n\ntreatment, resulting in a selection bias. \n\nIn addition, exclusion of subjects from statistical analysis because of noncompliance or missing \n\ndata could bias an estimate of the true benefit of a treatment, particularly if more patients were \n\nremoved from analysis in one group than the other (Everitt & Pickles, 1999). Much of the \n\nadvanced design strategies seek to reduce these systematic errors. \n\nConfounding \n\nConfounding represents the distortion of the true relationship between treatment and outcome \n\nby another factor, e.g., the severity of disease (Wang et al., 2006c). Confounding occurs when \n\nan extra factor is associated with both the outcome of interest and treatment group assignment. \n\nConfounding can both obscure an existing treatment difference and create an apparent \n\ndifference that does not exist. \n\nIf we divided patients into treatment groups based on inherent differences (such as mean age) \n\nat the start of a trial then we would be very likely to find the benefit of the new treatment to be \n\ninfluenced by those pre-existing differences. For example, if we assign only smokers to get \n\ntreatment A, only nonsmokers to get treatment B, and then assess which treatment protects \n\nbetter against cardiovascular disease, we might find that the benefit seen with treatment B is \n\ndue to the lack of smoking in this group. The effect of treatment B on cardiovascular disease \n\ndevelopment would therefore be confounded by smoking. \n\nRandomization in conjunction with a large sample size is the most effective way to restrict such \n\nconfounding, by evenly distributing both known and unknown confounding factors between \n\ntreatment groups. If, before the study begins, we know which factors may confound the trial \n\n \n \n                \n \n \n \n\fthen we can use randomization techniques that force a balance of these factors (stratified \n\nrandomization). In the analysis stage of a trial, we might be able to restrict confounding using \n\nspecial statistical techniques such as stratified analysis and regression analysis (Steele & Wang, \n\n2006). \n\nRandom error \n\nEven if a trial has an ideal design and is conducted to minimize bias and confounding, the \n\nobserved treatment effect could still be due to random error or chance (Wang et al., 2006). The \n\nrandom error can result from sampling, biologic, or measurement variation in outcome \n\nvariables. Since the patients in a clinical trial are only a sample of all possible available patients, \n\nthe sample might yet show a chance false result compared to the overall population. This is \n\nknown as a sampling error. Sampling errors can be reduced by choosing a very large group of \n\npatients. Other causes of random error are described elsewhere (Chow & Liu, 1998). \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f7. Statistics \n\nStatistics play a very important role in any clinical trial from design, conduct, analysis, and \n\nreporting in terms of controlling for and minimizing biases, confounding factors, and measuring \n\nrandom errors. The statistician generates the randomization code, calculates the sample size, \n\nestimates the treatment effect, and makes statistical inferences, so an appreciation of statistical \n\nmethods is fundamental to understanding randomized trial methods and results. Statistical \n\nanalyses deal with random error by providing an estimate of how likely the measured treatment \n\neffect reflects the true effect (Wang et al., 2006). Two statistical approaches are often used for \n\nclinical data analysis: hypothesis testing and statistical estimate. \n\nStatistics in Clinical Trials \n\nHypothesis Testing \n\nHypothesis testing or inference involves an assessment of the probability of obtaining an \n\nobserved treatment difference or more extreme difference for an outcome assuming that \n\nthere is no difference between two treatments (Altman, 1999; Kirkwood & Sterne, 2003; \n\nWang et al., 2006). This probability is often called the P-value or false-positive rate. If the P-\n\nvalue is less than a specified critical value (e.g., 5%), the observed difference is considered \n\nto be statistically significant. The smaller the P-value, the stronger the evidence is for a true \n\ndifference between treatments. On the other hand, if the P-value is greater than the \n\nspecified critical value then the observed difference is regarded as not statistically \n\nsignificant, and is considered to be potentially due to random error or chance. The \n\ntraditional statistical threshold is a P-value of 0.05 (or 5%), which means that we only \n\naccept a result when the likelihood of the conclusion being wrong is less than 1 in 20, i.e., \n\nwe conclude that only one out of a hypothetical 20 trials will show a treatment difference \n\nwhen in truth there is none. \n\nStatistical Estimate \n\nStatistical estimates summarize the treatment differences for an outcome in the forms of \n\npoint estimates (e.g., means or proportions) and measures of precision (e.g., confidence \n\nintervals [CIs]) (Altman, 1999; Kirkwood & Sterne, 2003; Wang et al., 2006). A 95% CI for \n\na treatment difference means that the range presented for the treatment effect contains \n\n(when calculated in 95 out of 100 hypothetical trials assessing the same treatment effect) \n\n \n \n                \n \n\fthe true value of treatment difference, i.e., the value we would obtain if we were to use the \n\nentire available patient population is 95% likely to be contained in the 95% CI. \n\nAlpha (Type I) and Beta (Type II) Errors \n\nWhen testing a hypothesis, two types of errors can occur. To explain these two types of errors, \n\nwe will use the example of a randomized, double-blind, placebo-controlled clinical trial on a \n\ncholesterol-lowering drug \u2018A\u2019 in middle-aged men and women considered to be at high risk for a \n\nheart attack. The primary endpoint is the reduction in the total cholesterol level at 6 months \n\nfrom randomization. \n\n Table 1: Alpha (Type I and Beta (Type II) Errors \n\nThe null hypothesis is that there is no difference in mean cholesterol reduction level at 6 months \n\npostdose between patients receiving drug A (\u03bc1) and patients receiving placebo (\u03bc2) (H0: \u03bc1 = \n\n\u03bc2); the alternative hypothesis is that there is a difference (Ha: \u03bc1 \u2260 \u03bc2). If the null hypothesis \n\nis rejected when it is in fact true, then a Type I error (or false-positive result) occurs. For \n\nexample, a Type I error is made if the trial result suggests that drug A reduced cholesterol levels \n\nwhen in fact there is no difference between drug A and placebo. The chosen probability of \n\ncommitting a Type I error is known as the significance level. As discussed above, the level of \n\nsignificance is denoted by \u03b1. In practice, \u03b1 represents the consumer\u2019s risk, which is often chosen \n\nto be 5% (1 in 20). \n\nOn the other hand, if the null hypothesis is not rejected when it is actually false, then a Type II \n\nerror (or false-negative result) occurs. For example, a Type II error is made if the trial result \n\nsuggests that there is no difference between drug A and placebo in lowering the cholesterol level \n\nwhen in fact drug A does reduce the total cholesterol. The probability of committing a Type II \n\n \n \n                \n \n \n \n \n \n\ferror, denoted by \u03b2, is sometimes referred to as the manufacturer\u2019s risk (Chow & Liu, 1998). \n\nThe power of the test is given by 1 \u2013 \u03b2, representing the probability of correctly rejecting the \n\nnull hypothesis when it is in fact false. It relates to detecting a pre-specified difference. \n\nRelationship Between Significant Testing and Confidence Interval \n\nWhen comparing, for example, two treatments, the purpose of significance testing is to assess \n\nthe evidence for a difference in some outcome between the two groups, while the CI provides a \n\nrange of values around the estimated treatment effect within which the unknown population \n\nparameter is expected to be with a given level of confidence. \n\nThere is a close relationship between the results of significance testing and CIs. This can be \n\nillustrated using the previously described cholesterol reduction trial. If H0: \u03bc1 = \u03bc2 is rejected at \n\nthe \u03b1% significance level, the corresponding (1 \u2013 \u03b1)% CI for the estimated difference (\u03bc1 - \u03bc2) \n\nwill not include 0. On the other hand, if H0: : \u03bc1 = \u03bc2 is not rejected at the \u03b1% significance \n\nlevel, then (1 \u2013 \u03b1)% CI will include 0. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f7. Statistics \n\nLet us assume that four randomized, double-blind, placebo-controlled trials are conducted to \n\nestablish the efficacy of two weight-loss drugs (A and B) against placebo, with all subjects, \n\nwhether on a drug or placebo, receiving similar instructions as to diet, exercise, behavior \n\nmodification, and other lifestyle changes. The primary endpoint is the weight change (kg) at 2 \n\nmonths from baseline. \n\nThe difference in the mean weight change between an active drug and placebo groups can be \n\nconsidered as weight reduction for the active drug against placebo. Table 2 presents the results \n\nof hypothesis tests and CIs for the four hypothetical trials. The null hypothesis for each trial is \n\nthat there is no difference between the active drug treatment and placebo in mean weight \n\nchange. \n\nIn trial 1 of drug A, the reduction of drug A over placebo was 6 kg with only 40 subjects in each \n\ngroup. The P-value of 0.074 suggests that there is no evidence against the null hypothesis of no \n\neffect of drug A at the 5% significance level. The 95% CI shows that the results of the trial are \n\nconsistent with a difference ranging from a large reduction of 12.6 kg in favor of drug A to a \n\nreduction of 0.6 kg in favor of placebo. \n\n Table 2: Point Estimate and 95% CI \n\nPoint estimate and 95% confidence interval (CI) for the difference in mean weight change from \n\nbaseline between the active drug and placebo groups in four hypothetical trials of two weight \n\nreduction drugs. \n\nThe results for trial 2 among 400 patients, again for drug A, suggest that mean weight was \n\nagain reduced by 6 kg. This trial was much larger, and the P-value (P < 0.001) shows strong \n\nevidence against the null hypothesis of no drug effect. The 95% CI suggests that the effect of \n\ndrug A is a greater reduction in mean weight over placebo of between 3.9 and 8.1 kg. Because \n\n \n \n                \n \n \n \n \n\fthis trial was large, the 95% CI was narrow and the treatment effect was therefore measured \n\nmore precisely. \n\nIn trial 3, for drug B, the reduction in weight was 4 kg. Since the P-value was 0.233, there was \n\nno evidence against the null hypothesis that drug B has no statistically significant benefit effect \n\nover placebo. Again this was a small trial with a wide 95% CI, ranging from a reduction of 10.6 \n\nkg to an increase of 2.6 kg for the drug B against the placebo. \n\nThe fourth trial on drug B was a large trial in which a relatively small, 2-kg reduction in mean \n\nweight was observed in the active treatment group compared with the placebo group. The P-\n\nvalue (0.008) suggests that there is strong evidence against the null hypothesis of no drug \n\neffect. However, the 95% CI shows that the reduction is as little as 0.5 kg and as high as 3.5 \n\nkg. Even though this is convincing statistically, any recommendation for its use should consider \n\nthe small reduction achieved alongside other benefits, disadvantages, and cost of this \n\ntreatment. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f7. Statistics \n\n Table 3: Key Points from Table 2 Trials \n\nSummary of the key points from the results described in Table 2 \n\nCI: confidence interval. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f7. Statistics \n\n Exercise 8: P-values and CI \n\n \n \n                \n \n\f \n \n                \n \n \n \n \n \n \n \n \n \n \n \n\f8. Summary \n\nThere has been an increasing number of randomized clinical trials conducted and published \n\nwhich provide the cornerstone of evidence-based medicine. More and more people from a broad \n\nrange of professional backgrounds need to understand the essentials of clinical trials regarding \n\ntheir design, statistical analysis, and reporting. In this chapter, we provided an introduction to \n\nthe area of clinical trials covering some of the key issues to be considered in their design, \n\nanalysis and interpretation. Firstly, we described the general aims of clinical trials and their \n\nclassifications according to different criteria. Secondly, we introduced some essential design \n\nissues in clinical trials, including endpoints, patient selection, protocol development, \n\nrandomization, blinding, and sample size determination. Thirdly, we discussed three possible \n\nsources of errors that may influence trial results: bias/systematic errors, confounding, and \n\nrandom error.  Next, we described some basic statistical concepts and methods frequently used \n\nin the analysis of randomized trials. These included descriptive statistics, statistical inferences, \n\ntechniques for the comparison of means or proportions from two samples, and survival analysis. \n\nTo facilitate understanding of the concepts, we also provided frequently used statistical terms \n\nand their meanings. In conclusion, readers should have sufficient knowledge, via the concepts \n\ndiscussed in this chapter, to appreciate the essential elements of most clinical trial reports. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f9. Glossary of Terms\n\nGLOSSARY \n\nBias \n\nSystematic errors associated with the inadequacies in the design, conduct, or analysis of a \n\ntrial on the part of any of the participants of that trial (patients, medical personnel, trial \n\ncoordinators or researchers), or in publication of its the results, that make the estimate of a \n\ntreatment effect deviate from its true value. Systematic errors are difficult to detect and \n\ncannot be analyzed statistically but can be reduced by using randomization, treatment \n\nconcealment, blinding, and standardized study procedures. \n\nConfidence Intervals \n\nA range of values within which the \"true\" population parameter (e.g. mean, proportion, \n\ntreatment effect) is likely to lie. Usually, 95% confidence limits are quoted, implying that \n\nthere is 95% confidence in the statement that the \"true\" population parameter will lie \n\nsomewhere between the lower and upper limits. \n\nConfounding \n\nA situation in which a variable (or factor) is related to both the study variable and the \n\noutcome so that the effect of the study variable on the outcome is distorted. For example, if \n\na study found that coffee consumption (study variable) is associated with the risk of lung \n\ncancer (outcome), the confounding factor here would be cigarette smoking, since coffee is \n\noften drunk while smoking a cigarette which is the true risk factor for lung cancer. Thus we \n\ncan say that the apparent association of coffee drinking with lung cancer is due to \n\nconfounding by cigarette smoking (confounding factor). In clinical trials, confounding occurs \n\nwhen a baseline characteristic (or variable) of patients is associated with the outcome, but \n\nunevenly distributed between treatment groups. As a result, the observed treatment \n\ndifference from the unadjusted (univariate) analysis can be explained by the imbalanced \n\ndistribution of this variable. \n\nCovariates \n\nThis term is generally used as an alternative to explanatory variables in the regression \n\n \n \n                \n \n\fanalysis. However, more specifically refer to variables that are not of primary interest in an \n\ninvestigation. Covariates are often measured at baseline in clinical trials because it is \n\nbelieved that they are likely to affect the outcome variable, and consequently need to be \n\nincluded to estimate the adjusted treatment effect. \n\nDescriptive/Inferential Statistics \n\nDescriptive statistics are used to summarize and describe data collected in a study. To \n\nsummarize a quantitative (continuous) variable, measures of central location (i.e. mean, \n\nmedian, and mode) and spread (e.g. range and standard deviation) are often used, whereas \n\nfrequency distributions and percentages (proportions) are usually used to summarize a \n\nqualitative variable. Inferential statistics are used to make inferences or judgments about a \n\nlarger population based on the data collected from a small sample drawn from the \n\npopulation. A key component of inferential statistics is hypothesis testing. Examples of \n\ninferential statistical methods are t-test and regression analysis. \n\nEndpoint \n\nClearly defined outcome associated with an individual subject in a clinical research. \n\nOutcomes may be based on safety, efficacy, or other study objectives (e.g. pharmacokinetic \n\nparameters). An endpoint can be quantitative (e.g. systolic blood pressure, cell count), \n\nqualitative (e.g. death, severity of disease), or time-to-event (e.g. time to first \n\nhospitalization from randomization). \n\nHazard Ratio \n\nIn survival analysis, hazard (rate) represents instantaneous event rate (incidence rate) at \n\ncertain time for an individual who has not experienced an event at that time. Hazard ratio \n\ncompares two hazards of having an event between two groups. If the hazard ratio is 2.0, \n\nthen the hazard of having an event in one group is twice the hazard in the other group. The \n\ncomputation of the hazard ratio assumes that the ratio is consistent over time (proportional \n\nhazards assumption). \n\nHypothesis Testing or Significance Testing \n\nStatistical procedure for assessing whether an observed treatment difference was due to \n\nrandom error (chance) by calculating a P-value using the observed sample statistics such as \n\nmean, standard deviation, etc. The P-value is the probability that the observed data or \n\n \n \n                \n\fmore extreme data would have occurred if the null hypothesis (i.e. no true difference) were \n\ntrue. If the calculated P-value is a small value (like <0.05), the null hypothesis is then \n\nrejected, and we state that there is a statistically significant difference. \n\nIntention-to-Treat Analysis \n\nA method of data analysis on the basis of the intention to treat a subject (i.e. the treatment \n\nregimen a patient was assigned at randomization) rather than the actual treatment regimen \n\nhe received. It has the consequence that subjects allocated to a treatment group should be \n\nfollowed up, assessed, and analyzed as members of that group regardless of their \n\ncompliance to that therapy or the protocol, irrespective of whether they later crossed over \n\nto the other treatment group or not or whether they discontinued treatment. \n\nKaplan-Meier Estimate and Survival Curve \n\nA survival curve shows an estimate of the fraction of patients who survive over the follow \n\nup period of the study without an event of interest (e.g. death). The Kaplan-Meier estimate \n\nis a simple way of computing the survival curve taking into account patients who were lost \n\nto follow up or any other reasons for incomplete results (known as censored observations). \n\nIt usually provides a staircase graph of the fraction of patients remaining free of event over \n\ntime. \n\nMeta-Analysis \n\nThe systematic review and evaluation of the evidence from two or more independent \n\nstudies asking the same clinical question to yield an overall answer to the question. \n\nNumber needed to treat (NNT) \n\nThis term is often used to describe how many patients would need to be given a treatment \n\nto prevent one event. It is determined from the absolute difference between one treatment \n\nand another. In a randomized study the group receiving treatment A had a death rate of \n\n12.5%, and the group receiving treatment B had a death rate of 15.0%. Both groups are \n\nmatched for size and length of follow-up. Comparing the two treatments there was an \n\nabsolute risk reduction of 15% - 12.5% = 2.5% for treatment A. From this we can derive \n\nthat the NNT (= 1/0.025) is 40. This means 40 patients need to be given treatment A rather \n\nthan B to prevent 1 additional death. \n\nOdds Ratio (OR) and Risk Ratio (RR) \n\n \n \n                \n\fThese terms compare the probability of having an event between two groups exposed to a \n\nrisk factor or treatment. The risk ratio (RR) is the ratio of the probability of occurrence of an \n\nevent between two groups. The odds ratio (OR) is the ratio of the ratio of patients with and \n\nwithout an event in each group. If the number of deaths in the treatment and control arms \n\n(both of sample size 100) of a randomized study are 50 and 25 respectively, the RR = \n\n(50/100) / (25/100) = 2. The treatment group has a 2- fold relative risk of dying compared \n\nwith the control group. The OR = (50/50) / (25/75) = 3 indicates that the odds of death in \n\nthe treatment arm is 3-fold of the control arm. \n\nPer-Protocol Analysis \n\nA method of analysis in which only the subset of subjects who complied sufficiently with the \n\nprotocol are included. Protocol compliance includes exposure to treatment, availability of \n\nmeasurements, correct eligibility, and absence of any other major protocol violations. This \n\napproach contrasts with the more conservative and widely accepted \"intention-to-treat\" \n\nanalysis. \n\nPower \n\nThe probability of rejecting the null hypothesis (e.g. no treatment difference) when it is \n\nfalse. It is the basis of procedures for calculating the sample size required to detect an \n\nexpected treatment effect of a particular magnitude. \n\nRandom Error \n\nAn unpredictable deviation of an observed value from a true value resulting from sampling \n\nvariability. It is a reflection of the fact that the sample is smaller than the population; for \n\nlarger samples, the random error is smaller, as opposed to systematic errors (bias) that \n\nkeep adding up because they all go in the same direction. \n\nRegression Analyses \n\nMethods of explaining or predicting outcome variables using information from explanatory \n\nvariables. Regression analyses are often used in clinical trials to estimate the adjusted \n\ntreatment effect taking into account of differences in baseline characteristics, and in \n\nepidemiological studies to identify prognostic factors while controlling for potential \n\nconfounders. Commonly used regression models include linear, logistic, and Cox regression \n\nmethods. \n\n \n \n                \n\fTreatment Effect \n\nAn effect attributed to a treatment in a clinical trial, often measured as the difference in a \n\nsummary measure of an outcome variable between treatment groups. Commonly expressed \n\nas difference in means for a continuous outcome, a risk difference, risk ratio, or odds ratio \n\nfor a binary outcome, and hazard ratio for a time-to-event outcome. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\f10. References \n\nAltman DG. (1999). Practical Statistics for medical research. London: Chapman and Hall. \n\nAltman DG, Schulz KF, Moher D, et al. (2001). The revised CONSORT statement for reporting \n\nrandomized trials: Explanation and elaboration. Ann Intern Med;134: 663\u201394. \n\nArezina R, Wang D. (2006). Source and control of bias. In: D Wang & A Bakhai, (Ed.s). Clinical \n\nTrials: A practical guide to design, analysis and reporting. London: Remedica. 55-64. \n\nBakhai A, Chhabra A, Wang D. (2006a). Endpoints. In: D Wang & A Bakhai, (Ed.s). Clinical \n\nTrials: A practical guide to design, analysis and reporting. London: Remedica. 37-45. \n\nBakhai A, Patel S, Wang D. (2006b). Blinding. In: D Wang & A Bakhai, (Ed.s). Clinical Trials: A \n\npractical guide to design, analysis and reporting. London: Remedica. 75-80. \n\nBakhai A, Sudhir R, Wang D. (2006c). Equivalence Trials.In: D Wang & A Bakhai, (Ed.s). Clinical \n\nTrials: A practical guide to design, analysis and reporting. London: Remedica. 113-118. \n\nChow SC, Liu JP. (1998). Design and analysis of clinical trials: Concept and methodologies. \n\nChichester: John Wiley & Sons. \n\nChow SC, Shao J, Wang H. (2003). Sample size calculation in clinical research. New York: \n\nMarcel. \n\nChow SC, Shao J, and Wang, H (2007). Sample size calculations in clinical research. 2nd edition. \n\nChapman Hall/CRC Press, Taylor & Francis: New York. \n\nCox DR, Oakes D. (1984). Analysis of survival data. London: Chapman and Hall. \n\nDay S. (1999). Dictionary of clinical trials. Chichester: John Wiley & Sons. \n\nDeclaration of Helsinki. Ethical Principles for Medical Research Involving Human Subjects. \n\nAvailable from: http://www.wma.net/en/30publications/10policies/b3/index.html. Accessed May \n\n6, 2005. \n\nDirective 2001/20/EC of the European Parliament and of the Council of 4 April 2001 on the \n\napproximation of the laws, regulations and administrative provisions of the Member States \n\n \n \n                \n\frelating to the implementation of good clinical practice in the conduct of clinical trials on \n\nmedicinal products for human use. Official Journal of the European Union 2001;121:34. \n\nEveritt BS, Pickles A. (1999). Statistical aspects of the design and analysis of clinical trials. \n\nLondon: Imperial College Press. \n\nFDA, Regulations Relating to Good Clinical Practice and Clinical Trials. Available from: \n\nhttp://www.fda.gov/oc/gcp/regulations.html. Accessed May 6, 2005. \n\nFDA, Section 5.8 of the International Conference on Harmonization: Guidance on Statistical \n\nPrinciples for Clinical Trials. Available from: \n\nhttp://www.fda.gov/ScienceResearch/SpecialTopics/RunningClinicalTrials/ucm114928.htm. \n\nAccessed March 31, 2005. \n\nFox Z, et al. (2006). Factorial design. In: D Wang & A Bakhai, (Ed.s). Clinical Trials: A practical \n\nguide to design, analysis and reporting. London: Remedica. 101-112. \n\nFriedman LM, Furberg CD, Demets D. (1998). Fundamentals of clinical trials, 3rd edition. New \n\nYork: Springer Verlag. \n\nInternational Conference on Harmonisation. E6: Good Clinical Practice: Consolidated Guidelines. \n\nAvailable from:http: http://www.ich.org/cache/compo/276-254-1.html. Accessed May 6, 2005. \n\nJadad AR. (1998). Randomized controlled trials: A user\u2019s guide. London: BMJ Books. \n\nJones B, Kenward MG. (2003). Design and analysis of cross-over trials, 2nd edition. London: \n\nChapman and Hall/CRC. \n\nKirkwood B, Sterne J. (2003). Essential medical statistics, 2nd edition. Oxford: Blackwell \n\nPublishing. \n\nMallick U, et al. (2006a). Protocol development. In: D Wang & A Bakhai, (Ed.s). Clinical Trials: A \n\npractical guide to design, analysis and reporting. London: Remedica. 23-36. \n\nMallick U, et al. (2006b). Cluster randomized trials. In: D Wang & A Bakhai, (Ed.s). Clinical \n\nTrials: A practical guide to design, analysis and reporting. London: Remedica.141-151. \n\nMatthews JNS. (2000). Introduction to randomized controlled clinical trials. London: Arnold. \n\n \n \n                \n\fMiller S, Neate C, Wang D. (2006). Noninferiority trials. In: D Wang & A Bakhai, (Ed.s). Clinical \n\nTrials: A practical guide to design, analysis and reporting. London: Remedica. 131-140. \n\nPocock SJ. (1983). Clinical trials: A practical approach. Chichester: John Wiley & Sons. \n\nSenn S. (2002). Cross-over trials in clinical research, 2nd edition. Chichester: John Wiley & \n\nSons. \n\nSteele, F. Wang, D. (2006). Regression Analyses. In: D Wang & A Bakhai A, (Ed.s). Clinical \n\ntrials: A practical guide to design, analysis and reporting. London: Remedica. 273-286. \n\nTruesdale A, Bakhai A, Wang D. (2006). Multicenter trials. In: D Wang & A Bakhai, (Ed.s). \n\nClinical trials: A practical guide to design, analysis and reporting. London: Remedica. 153-163. \n\nWang D & Bakhai A, editors. (2006). Clinical Trials: A Practical Guide to Design, Analysis and \n\nReporting. London: Remedica. \n\nWang D, Bakhai A. (2006a). Randomization. In: D Wang & A Bakhai, (Ed.s). Clinical trials: A \n\npractical guide to design, analysis and reporting. London: Remedica. 65-73. \n\nWang D, Bakhai A. (2006b). Sample Size and Power. In: D Wang & A Bakhai, (Ed.s). Clinical \n\ntrials: A practical guide to design, analysis and reporting. London: Remedica. 81-87. \n\nWang D, Arezina R, Bakhai A. (2006a). Bioequivalence Trials. In: D Wang & A Bakhai, (Ed.s). \n\nClinical trials: A practical guide to design, analysis and reporting. London: Remedica. 119-130. \n\nWang D, Clayton T, Bakhai A. (2006b). Analysis of Survival Data. In: D Wang & A Bakhai, \n\n(Ed.s). Clinical trials: A practical guide to design, analysis and reporting. London: Remedica. \n\n235-254. \n\nWang D. Clayton T, Bakhai A. (2006c). Confounding. In: D Wang & A Bakhai, (Ed.s). Clinical \n\ntrials: A practical guide to design, analysis and reporting. London: Remedica. 295-304. \n\nWang D, Clayton T, Clemens F. (2006d). Comparison of Proportions. In: D Wang & A Bakhai, \n\n(Ed.s). Clinical trials: A practical guide to design, analysis and reporting. London: Remedica. \n\n217-234. \n\n \n \n                \n\fWang D, Clayton T, Yan H. (2006e). Significance Tests and Confidence Intervals. In: D Wang & \n\nA Bakhai, (Ed.s). Clinical trials: A practical guide to design, analysis and reporting. London: \n\nRemedica. 185-196. \n\nWang D, Clemens F, Clayton T. (2006f). Comparison of Means. In: D Wang & A Bakhai, (Ed.s). \n\nClinical trials: A practical guide to design, analysis and reporting. London: Remedica. 197-216. \n\nWang D, Lorch U, Bakhai A. (2006g). Crossover Trials. In: D Wang & A Bakhai, (Ed.s). Clinical \n\ntrials: A practical guide to design, analysis and reporting. London: Remedica. 91-99. \n\nYusuf S, Zhao F, Mehta SR et al. (2001). Effects of clopidogrel in addition to aspirin in patients \n\nwith acute coronary syndromes without ST-segment elevation. N Engl J Med;345: 494\u2013502. \n\n \n \n                \n \n \n \n \n \n \n \n \n \n\f11. Author Biographies \n\nDuolao Wang, MSc, PhD is a senior lecturer in medical statistics at Medical Statistics Unit, \n\nLondon School of Hygiene and Tropical Medicine, University of London, UK. Dr. Wang is an \n\napplied statistician with research interests centering on application of state-of-the-art \n\nmathematical and statistical models and techniques to discover substantive facts and/or assess \n\ntheories about medical, biological, demographic, environmental and social determinants of \n\ndisease and health. His research interests include: (1) health intervention studies and clinical \n\ntrials; (2) reproductive health, demography and epidemiology; (3) statistical methodology and \n\ncomputing. \n\nHe has published more than 80 articles on medical and epidemiological research as well as \n\nstatistical methodology in peer-reviewed journals including NEJM, JAMA, Circulation, American \n\nHeart Journal, European Heart Journal, Gut, Human Reproduction, Demography, Population \n\nStudies, Journal of Applied Statistics, and Statistics in Medicine, etc. He is a co-author of the \n\nbook \"Clinical Trials: A Practical Guide to Design, Analysis and Reporting\", which has sold over \n\n15,000 copies worldwide since its publication in January 2006. \n\nAmeet Bakhai, MD, MRCP is a consultant cardiologist and physician at Barnet General & Royal \n\nFree Hospitals, London, UK. Dr Bakhai has particular experience in design, conduct, and analysis \n\nof clinical trials, registry studies, and health technology assessments at a national and \n\ninternational level. He has worked in clinical trials for 7 years, directing coronary intervention \n\ntrials and leading collaborative Health Technology Assessments commissioned for groups such \n\nas the UK National Institute for Clinical Excellence. He has over 50 publications and gained \n\nstatistical, trial, and economic evaluation expertise at the Harvard Clinical Research Institute. He \n\nis also a director of the Asha Medical Outcomes Research and Economic (AMORE) studies group. \n\nDr Bakhai has also been involved in the promotion and evaluation of guideline-based clinical \n\npractice. His research interests include health economics, interventional trials, acute coronary \n\nsyndromes, and statistics. His specific focus is on enabling the use of guidelines with health \n\neconomic data to overcome common barriers. \n\n \n \n                \n \n \n \n\f",
  "file_path": "/home/runner/workspace/attached_assets/Clinical-Trials.pdf",
  "sampleSize": 0,
  "randomization": "Unknown",
  "studyDesign": "Unknown",
  "interventionalModel": "Unknown",
  "primaryPurpose": "Unknown",
  "maskingInfo": "Unknown"
}